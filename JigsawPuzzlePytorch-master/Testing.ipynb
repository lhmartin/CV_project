{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Aug 18 11:58:07 2017\n",
    "\n",
    "@author: Biagio Brattoli\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_max = 96\n",
    "tile = 25\n",
    "puzzle_full = 75\n",
    "\n",
    "class DataLoader(data.Dataset):\n",
    "    def __init__(self, data_path, txt_list, classes=1000):\n",
    "        self.data_path = data_path\n",
    "        self.names, _ = self.__dataset_info(txt_list)\n",
    "        self.N = len(self.names)\n",
    "        self.permutations = self.__retrive_permutations(classes)\n",
    "\n",
    "        self.__image_transformer = transforms.Compose([\n",
    "            transforms.Resize(img_max, Image.BILINEAR),\n",
    "            transforms.CenterCrop(img_max - 1)])\n",
    "        self.__augment_tile = transforms.Compose([\n",
    "            transforms.RandomCrop(tile - 4),\n",
    "            transforms.Resize((25, 25), Image.BILINEAR),\n",
    "            transforms.Lambda(rgb_jittering),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            # std =[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        \n",
    "        if np.random.rand() < 0.30:\n",
    "            img = img.convert('LA').convert('RGB')\n",
    "\n",
    "        if img.size[0] != img_max:\n",
    "            img = self.__image_transformer(img)\n",
    "\n",
    "        s = float(img.size[0]) / 3\n",
    "        print(s)\n",
    "        a = s / 2\n",
    "        tiles = [None] * 9\n",
    "        \n",
    "        for n in range(9):\n",
    "            i = n / 3\n",
    "            j = n % 3\n",
    "            c = [a * i * 2 + a, a * j * 2 + a]\n",
    "            c = np.array([c[1] - a, c[0] - a, c[1] + a + 1, c[0] + a + 1]).astype(int)\n",
    "            tile = img.crop(c.tolist())\n",
    "            tile = self.__augment_tile(tile)\n",
    "            # Normalize the patches indipendently to avoid low level features shortcut\n",
    "            m, s = tile.view(3, -1).mean(dim=1).numpy(), tile.view(3, -1).std(dim=1).numpy()\n",
    "            s[s == 0] = 1\n",
    "            norm = transforms.Normalize(mean=m.tolist(), std=s.tolist())\n",
    "            tile = norm(tile)\n",
    "            tiles[n] = tile\n",
    "\n",
    "        order = np.random.randint(len(self.permutations))\n",
    "        data = [tiles[self.permutations[order][t]] for t in range(9)]\n",
    "        data = torch.stack(data, 0)\n",
    "\n",
    "        return data, int(order), tiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __dataset_info(self, txt_labels):\n",
    "        with open(txt_labels, 'r') as f:\n",
    "            images_list = f.readlines()\n",
    "        \n",
    "        file_names = []\n",
    "        labels = []\n",
    "        for row in images_list:\n",
    "            row = row.split('\\n')\n",
    "            file_names.append(row[0])\n",
    "            labels.append(int(1))\n",
    "\n",
    "        return file_names, labels\n",
    "\n",
    "    def __retrive_permutations(self, classes):\n",
    "        all_perm = np.load('permutations_%d.npy' % (classes))\n",
    "        # from range [1,9] to [0,8]\n",
    "        if all_perm.min() == 1:\n",
    "            all_perm = all_perm - 1\n",
    "\n",
    "        return all_perm\n",
    "\n",
    "\n",
    "def rgb_jittering(im):\n",
    "    im = np.array(im, 'int32')\n",
    "    for ch in range(3):\n",
    "        im[:, :, ch] += np.random.randint(-2, 2)\n",
    "    im[im > img_max] = img_max\n",
    "    im[im < 0] = 0\n",
    "    return im.astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = \"../sslime/extra_scripts/data\"\n",
    "\n",
    "trainpath = ad +'/train'\n",
    "train_data = DataLoader(trainpath, ad +'/train.txt',\n",
    "                            classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                            batch_size= 1,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x2adbca0c82e8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lhm300/.conda/envs/slime_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/lhm300/.conda/envs/slime_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/lhm300/.conda/envs/slime_env/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "32.0\n",
      "i =  0\n",
      "torch.Size([1, 9, 3, 25, 25])\n",
      "torch.Size([1])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels, original) in enumerate(train_loader):\n",
    "    print(\"i = \", i)\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(original))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 25, 25])\n"
     ]
    }
   ],
   "source": [
    "print(images[0][0][:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 25, 3])\n"
     ]
    }
   ],
   "source": [
    "print(np.reshape(images[0][0][:], (25,25,3)).shape)\n",
    "img = np.reshape(images[0][0][:], (3,25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-slime_env] *",
   "language": "python",
   "name": "conda-env-.conda-slime_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
